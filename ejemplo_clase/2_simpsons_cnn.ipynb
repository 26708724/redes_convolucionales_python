{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67RBrvkUviuj"
   },
   "source": [
    "<a href=\"https://www.inove.com.ar\"><img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/PA%20Banner.png\" width=\"1000\" align=\"center\"></a>\n",
    "\n",
    "\n",
    "# Ejercicio de clasificación con redes neuronales convolucionales (CNN)\n",
    "\n",
    "Ejemplo de clasificación utilizando redes neuronales convolucionales para la clasificación de imagenes<br>\n",
    "\n",
    "v1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2sSeyEovSw-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "#from keras.utils import to_categorical\n",
    "from keras.utils.np_utils import to_categorical # Si esto no funciona, probar con el import anterior\n",
    "\n",
    "from glob import glob\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Szo7P_3v00C"
   },
   "source": [
    "# Recolectar datos\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline1.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbNSgxdfw0ix"
   },
   "source": [
    "### `Simpsons dataset`:\n",
    "El dataset **`Simpsons`** contiene 550Mbytes de imagenes a color de los personajes de los Simpsons (47 personajes). Cada imagen es de tiene al rededor de 500x450 píxeles a color (3 canales).<br> [Dataset source](https://www.kaggle.com/paultimothymooney/zipfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UNMvYZYiqdhc",
    "outputId": "d7c6749d-d543-45f2-aace-ca3a4980491e"
   },
   "outputs": [],
   "source": [
    "# Descargar la carpeta imagenes simpsons\r\n",
    "import gdown\r\n",
    "if os.access('./simpsons_dataset', os.F_OK) is False:\r\n",
    "    if os.access('simpsons_dataset.zip', os.F_OK) is False:\r\n",
    "        url = 'https://drive.google.com/uc?id=1mn7cuJ4VudbF1HshbWnvsivSk5o8qAn2'\r\n",
    "        output = 'simpsons_dataset.zip'\r\n",
    "        gdown.download(url, output, quiet=False)\r\n",
    "    !unzip -q simpsons_dataset.zip   \r\n",
    "else:\r\n",
    "    print(\"La carpeta ya se encuentra descargada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39D74GHn9hi1",
    "outputId": "017851c3-5ef3-4883-fcbb-f76964ce2fb1"
   },
   "outputs": [],
   "source": [
    "# Visualizar los directiorios o tipos de personas\n",
    "os.listdir(\"./simpsons_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ywRZdgPa97sk",
    "outputId": "b7113d6e-1615-4112-f22a-77d9c5727211"
   },
   "outputs": [],
   "source": [
    "personajes = os.listdir(\"./simpsons_dataset\")\n",
    "print(\"Cantidad de tipos de personaejs:\", len(personajes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "rGbCJanFR8oL",
    "outputId": "ce32f629-03e9-4f90-b8d1-eda155312e20"
   },
   "outputs": [],
   "source": [
    "# Visualizar las 10 primeras imagenes de un personaje\n",
    "files = glob(\"./simpsons_dataset/\" + personajes[0] + \"/**.jpg\")\n",
    "\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(2, 5, i+1)\n",
    "    ax.axis('off')\n",
    "    img = mpimg.imread(files[i])\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fYGanqnC_Ppw",
    "outputId": "7cbb89da-0937-4811-bd37-9205ca05f27a"
   },
   "outputs": [],
   "source": [
    "# Visualizar la dimension de la primera imagen\n",
    "img = mpimg.imread(files[0])\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "syeZ_UKH_Wsm",
    "outputId": "69076c47-14d6-482a-df28-63ea96d4e2ab"
   },
   "outputs": [],
   "source": [
    "# Visualizar como están representados los pixeles\n",
    "print(img[85, 100:110, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xF62E6R5_lDh"
   },
   "source": [
    "#### Conclusiones\n",
    "- Las imagenes tienen tamaño variable, utilizaremos un tamaño reducido para que todas las imagenes sean iguales (se elije 150x150)\n",
    "- Las imagenes están representadas de 0 a 255, hay que normalizarlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_NjEA__fLBk",
    "outputId": "6d17d894-46d4-44cc-9931-e51caf022c9c"
   },
   "outputs": [],
   "source": [
    "# Descargar datos de test\n",
    "if os.access('simpsons_test', os.F_OK) is False:\n",
    "    if os.access('simpsons_test.zip', os.F_OK) is False:\n",
    "        if platform.system() == 'Windows':\n",
    "            !curl https://github.com/InoveAlumnos/dataset_analytics_python/raw/master/simpsons_test.zip > simpsons_test.zip\n",
    "        else:\n",
    "            !wget simpsons_test.zip https://github.com/InoveAlumnos/dataset_analytics_python/raw/master/simpsons_test.zip\n",
    "    !unzip -q simpsons_test.zip\n",
    "else:\n",
    "    print(\"El archivo ya se encuentra descargado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHHsGe1Qypde"
   },
   "source": [
    "# Procesar datos\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline2.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uvzaKBMbyoiy",
    "outputId": "3d10ed57-6988-4639-920c-4d13a70c7caf"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Crear un generador, indicando si deseamos realizar un escalado de la imagen\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        directory=\"./simpsons_dataset\",\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode=\"categorical\")\n",
    "\n",
    "index_to_classes = dict(zip(train_generator.class_indices.values(), train_generator.class_indices.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BnzYdlRzBxz"
   },
   "source": [
    "# Explorar datos\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline3.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vV05awstE6RX"
   },
   "outputs": [],
   "source": [
    "# El generador \"train_generator\" se lo puede utilizar para acceder a los datos\n",
    "# de a cantidad batch de imagenes. En este caso el generador me retornará\n",
    "# la primera vez las primeras 20 imagenes\n",
    "# El generador devuelve las imagenes (X) y las clases(personaes) a las que\n",
    "# pertenece (y)\n",
    "# X, y = train_generator.next()\n",
    "batch_imagenes, batch_clases = train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9jbktbPF7u3",
    "outputId": "b3f3a2c4-d24c-4df0-ee12-fe895071a7fd"
   },
   "outputs": [],
   "source": [
    "batch_imagenes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KmdCnAQ2Kd7x",
    "outputId": "b91e794b-7b9d-4716-9e14-2f88801007a3"
   },
   "outputs": [],
   "source": [
    "batch_clases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGCIcOPSGSk1",
    "outputId": "dd6d547d-4ed6-40b5-f157-55c5d1150e87"
   },
   "outputs": [],
   "source": [
    "print(\"Cantidad de imagenes en el batch:\", batch_imagenes.shape[0])\n",
    "print(\"Dimensión de la imagen:\", batch_imagenes.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u_jnc_dqKgCt",
    "outputId": "7052c900-e838-4f93-e79f-f94309e056c0"
   },
   "outputs": [],
   "source": [
    "print(\"Cantidad de clases/personajes:\", batch_clases.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "dUbEzgZsGfDB",
    "outputId": "4421c280-75a4-42a7-b379-d97dad693adf"
   },
   "outputs": [],
   "source": [
    "# Observar las primeras 5 imagenes de ese batch\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "for i in range(5):\n",
    "    ax = fig.add_subplot(1, 5, i+1)\n",
    "    ax.imshow(batch_imagenes[i])\n",
    "    numero_clase = batch_clases[i].argmax()\n",
    "    ax.set_title(index_to_classes[numero_clase])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmZRSSv1JPMz"
   },
   "source": [
    "__Importante__! Luego de usar un generador \"jugando\", ese batch de imagenes que sacamos ya no se encontrará disponible para ser utilizado en el entrenamiento, es recomendable volver a crear los generadores si se los consumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wt_1BC0cKEcz",
    "outputId": "1a42a123-a33d-482c-d871-9106425d3603"
   },
   "outputs": [],
   "source": [
    "# Crear un generador, indicando si deseamos realizar un escalado de la imagen\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        directory=\"./simpsons_dataset\",\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode=\"categorical\")\n",
    "\n",
    "index_to_classes = dict(zip(train_generator.class_indices.values(), train_generator.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7z_SuZlj3gbQ"
   },
   "source": [
    "# Entrenar modelo\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline4.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vdIz9_r-sMe"
   },
   "outputs": [],
   "source": [
    "# Los generadores ya que encargan de transformar la salida a oneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Wb3oMvn-mIF",
    "outputId": "a8857012-0247-446c-fafe-6b8ccc6508d0"
   },
   "outputs": [],
   "source": [
    "# input shape (observado del análisis de datos)\n",
    "in_shape = (150, 150, 3)\n",
    "in_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpYcXh1g_N3Q",
    "outputId": "fcbc6545-7612-4295-9892-41da2c583464"
   },
   "outputs": [],
   "source": [
    "# output shape (observado del análisis de datos)\n",
    "out_shape = 42\n",
    "out_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pQ8tQk2DMgBd",
    "outputId": "b0e1d03a-db15-4a09-ce3a-554902774950"
   },
   "outputs": [],
   "source": [
    "# Debemos definir cuantas imagenes se consumiran por epoca (steps_per_epoch)\n",
    "# ya que estando el generador en el medio Keras no puede saberlo por\n",
    "# su cuenta\n",
    "steps_per_epoch_train = len(train_generator)\n",
    "steps_per_epoch_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WoPKBgrKYh3F",
    "outputId": "e87e18e7-d64b-49fa-973c-3202a4931d9a"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "# Primero realizaremos un modelo muy simple con una solo par de CONV + POOL\n",
    "# tal cual se utilizo en los otros notebooks de dataset más simples\n",
    "\n",
    "model1.add(Conv2D(filters=8, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu', input_shape=in_shape))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(units=64, activation='relu'))\n",
    "model1.add(Dense(units=out_shape, activation='softmax'))\n",
    "\n",
    "model1.compile(optimizer=\"Adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GT_IpBOkYyor"
   },
   "source": [
    "Se puede observar que esta red tiene más de 2 millones de parámetros para entrenar!!\\\n",
    "Esto es porque la capa densa de POOL de 75x75x8 se transforma a un flatten\n",
    "de 450000 neuronaes (75x75x8 = 45000) que luego se conectan con todas las \n",
    "neuroanes de la capa sigueinte (64) --> 45000x64 + 64 = 2880064\\\n",
    "Para bajar la cantidad de parametros debemos seguir comprimiendo la imagen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-d7Yw_aYsM0",
    "outputId": "ae7ab4a3-6299-4494-a85b-a9db057275ff"
   },
   "outputs": [],
   "source": [
    "history1 = model1.fit(train_generator, steps_per_epoch=steps_per_epoch_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "lhf9z3PkYuog",
    "outputId": "a4234324-cb80-470d-cd3f-392dd0a767c7"
   },
   "outputs": [],
   "source": [
    "epoch_count = range(1, len(history1.history['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=history1.history['accuracy'], label='train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fu1u9JhXq9Dy",
    "outputId": "bc468901-244f-4fb6-e863-75e846a6cb69"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "# Ahora agregaremos más pares de capas CONV + POOL a fin de reducir más la\n",
    "# dimensión de la imagen antes de llegar a la capa flatten\n",
    "# Otra estrategia es ir aumentando la cantidad de filtros a medida que crece\n",
    "# la profundidad de la red\n",
    "\n",
    "# convolucional f=(3,3), # de filtros: 8, activación relu\n",
    "# max pooling f=2, s=2\n",
    "model2.add(Conv2D(filters = 8, kernel_size = (3, 3), strides=1, padding='same', activation='relu', input_shape=(150, 150, 3)))\n",
    "model2.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "# convolucional f=(3,3), # de filtros: 16, activación relu\n",
    "# max pooling f=2, s=2\n",
    "model2.add(Conv2D(filters = 16, kernel_size = (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "# convolucional f=(3,3), # de filtros: 32, activación relu\n",
    "# max pooling f=2, s=2\n",
    "model2.add(Conv2D(filters = 32, kernel_size = (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "# convolucional f=(3,3), # de filtros: 64, activación relu\n",
    "# max pooling f=2, s=2\n",
    "model2.add(Conv2D(filters = 64, kernel_size = (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "# capa flatten\n",
    "model2.add(Flatten())\n",
    "# capa densa de 64 elementos activación relu\n",
    "model2.add(Dense(units=128, activation='relu'))\n",
    "model2.add(Dropout(rate=0.2))\n",
    "# capa densa con un output de 10 elemento con activación softmax\n",
    "model2.add(Dense(units=out_shape, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer=\"Adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_89g3dSm2wf",
    "outputId": "e3ce632f-f325-4bcd-8741-7333c2282ecf"
   },
   "outputs": [],
   "source": [
    "history2 = model2.fit(train_generator, steps_per_epoch=steps_per_epoch_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "xDuagYJHvNlm",
    "outputId": "7760d2d1-7d63-4ad1-c824-2a1310243972"
   },
   "outputs": [],
   "source": [
    "epoch_count = range(1, len(history2.history['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=history2.history['accuracy'], label='train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EsH5q9y6Qt1-",
    "outputId": "e1687b49-a811-4c4d-854b-deb640b9281d"
   },
   "outputs": [],
   "source": [
    "# Predecir los datos\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        directory=\"./simpsons_test\",\n",
    "        target_size=(150, 150),\n",
    "        batch_size=10,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "y_hat_prob = model2.predict(test_generator)\n",
    "y_hat_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qxs4EZSBAZoh",
    "outputId": "88efb867-a173-4331-ecd3-2d9008abe664"
   },
   "outputs": [],
   "source": [
    "y_hat = np.argmax(y_hat_prob,axis=1)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBqoGBsIS4Rr",
    "outputId": "35fd98db-19c7-4aba-8806-c397f33d3bfa"
   },
   "outputs": [],
   "source": [
    "#¿Cómo obtenemos el \"y\" verdadero?\n",
    "test_generator.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AaIy0eJFS_bn",
    "outputId": "231c2d94-a229-4e33-f06d-ab5e921d1a4a"
   },
   "outputs": [],
   "source": [
    "# Muy rebuscada esta forma de obtener los nombres de los personajes!\n",
    "# Pero en general cuando tenemos los datos de test no tenemos los nombres\n",
    "# por lo que no tenemos el \"y\" verdadero\n",
    "personajes_test = []\n",
    "for file in test_generator.filenames:\n",
    "    image_name = os.path.basename(file)\n",
    "    image_name_split = image_name.split(\"_\")\n",
    "    personaje_name_split = image_name_split[:len(image_name_split)-1]\n",
    "    personaje = personaje_name_split[0]\n",
    "    for name in personaje_name_split[1:]:\n",
    "        personaje += \"_\" + name\n",
    "    personajes_test.append(personaje)\n",
    "personajes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eUeviz_CUXlK",
    "outputId": "1a36dfea-dd30-423c-d266-beaff44cea15"
   },
   "outputs": [],
   "source": [
    "# Obtener el \"y\" verdadero\n",
    "y_test = [train_generator.class_indices[personaje] for personaje in personajes_test]\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ww_S7M1lw9oT"
   },
   "outputs": [],
   "source": [
    "# Descargar el modelo entrenado para usar en el futuro sin tener\n",
    "# que volver a entrenarlo\n",
    "model2.save(\"cnn_simpsons.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3IfjUuI4XnD"
   },
   "source": [
    "# Validar modelo\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline5.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HnXeXHwdyHVx",
    "outputId": "bb242e94-50fd-463f-b7ee-a22df4e12828"
   },
   "outputs": [],
   "source": [
    "# Calcular la exactitud (accuracy)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "TeLeYLYz6ZhO",
    "outputId": "1217fde3-9a5e-4199-d034-3684a1233ce0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_hat)\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=range(47))\n",
    "cmd.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dZxGbjG96jR"
   },
   "source": [
    "# Utilizar modelo\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline6.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noOsuU6Tb4GZ"
   },
   "outputs": [],
   "source": [
    "batch_test = test_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "Cefy3ktFb6j6",
    "outputId": "cd7fcdc0-4588-47f2-b7d6-299d5409bfe1"
   },
   "outputs": [],
   "source": [
    "# Observar las primeras 5 imagenes de ese batch\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(2, 5, i+1)\n",
    "    ax.imshow(batch_test[i])\n",
    "    numero_clase = y_hat[i]\n",
    "    ax.set_title(index_to_classes[numero_clase])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7yzVZcZ9-4m"
   },
   "source": [
    "# Conclusión\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline7.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWAReOgo-B7b"
   },
   "source": [
    "Al utilizar más pares de capas CONV+POOL se pudo obtener un mejor resultado, un modelo casi perfecto. Hay que tener en cuenta que el dataset de test es muy pequeño y hay muchos otros personajes que no estamos clasificando."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2_simpsons_cnn.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
